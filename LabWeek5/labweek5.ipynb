{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J557BiV2XtNG"
   },
   "source": [
    "## Classifying movie reviews: A binary classification example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eLYFyAhpXtNH"
   },
   "source": [
    "## The IMDB dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qEqwCl4PXtNH"
   },
   "source": [
    "### Loading the IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sbrqXqS3XtNH"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(\n",
    "    num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C5-3DHlRYr6T"
   },
   "source": [
    "### Explore the data\n",
    "1. Print `trian_data`\n",
    "2. Find the data type.\n",
    "3. Find the shape.\n",
    "4. Print out one sample from the `train_data`\n",
    "5. The sample data is a list. What is the length of the list\n",
    "6. Repeat the step `4` and `5` for another data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cxi5Q2b5r9QT"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kg7raoDqdSTq"
   },
   "source": [
    "Each data point in the dataset represents a sequence of words encoded to numbers.\n",
    "\n",
    "We will see how this encoding process is.\n",
    "\n",
    "**Find the longest sequence in the train_data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GUNrVv4WeC-U"
   },
   "source": [
    "**Find the largest number in all sequences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1OjCMyh2bf8p"
   },
   "source": [
    "### What do the numerical features represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GnzxgirbbyRR"
   },
   "outputs": [],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "print(word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZwWZhs9ecDvY"
   },
   "source": [
    "**Sort the word_index dictionary based on the value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yEBZPEi9sFwY"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C02xDdrqdAxo"
   },
   "source": [
    "**How many words are there in the dictionary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "M2anCHYEePWD"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "slkEqDyPXtNJ"
   },
   "source": [
    "### Decoding reviews back to text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xhORg5FKa5Ly"
   },
   "source": [
    "When the IMDB dataset is preprocessed, each actual word's index is offset by 3. That means if a word originally had an index `i` in the word_index, it will appear as `i + 3` in `train_data`. Indices `0`, `1`, and `2` are reserved for special tokens like padding and unknown words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t618lbm8efbw"
   },
   "source": [
    "**Use your programing knowledge to decode the first train data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "k8YccRWHevgw"
   },
   "outputs": [],
   "source": [
    "## your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "lYleNvd8XtNJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n"
     ]
    }
   ],
   "source": [
    "#Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ICkRcO6-hdsU"
   },
   "source": [
    "**Encoding: sequence of words -> encoded to sequence of integer numbers (`tokens`) in range(0, 10000)**\n",
    "\n",
    "**Decoding: sequence of tokens -> decoded to sequence words**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x5JPGLOxXtNJ"
   },
   "source": [
    "### Preparing the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9bJyBdOKXtNJ"
   },
   "source": [
    "**Encoding the integer sequences via multi-hot encoding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ShQh9N_fPFk"
   },
   "source": [
    "**Note:**In the previous part we saw that the largest number in all sequences is `9999`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VhWA-pWHXtNK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        for j in sequence:\n",
    "            results[i, j] = 1.\n",
    "    return results\n",
    "x_train_emb = vectorize_sequences(train_data)\n",
    "x_test_emb = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wkRKKPwKXtNK"
   },
   "outputs": [],
   "source": [
    "x_train_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gFX53od2XtNK"
   },
   "outputs": [],
   "source": [
    "y_train = np.asarray(train_labels).astype(\"float32\")\n",
    "y_test = np.asarray(test_labels).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CoyzqpKKjm44"
   },
   "source": [
    "**Encoding: sequence of words -> encoded to sequence of integer numbers (`tokens`) in range(0, 10000)**\n",
    "\n",
    "**Embedding: sequence of tokens -> multi-hot vector**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gomcTBZSkioY"
   },
   "source": [
    "## ML Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I2VQfKbLkoc8"
   },
   "source": [
    "**Task:**\n",
    "Our neural network model should get the embedded vector of a review and assign label 0 if the review is negative or 1 if the review is positive.\n",
    "\n",
    "**Note:** This task is called `sentiment analysis` task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iHZ2Ztz5XtNK"
   },
   "source": [
    "### Building your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LkDW6zHpXtNK"
   },
   "source": [
    "**Model definition**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mqw-BkdEkRdk"
   },
   "source": [
    "model containing `2` hidden layers with `16` units and output layer with `1` unit. Select the suitable activation function for each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EooZQmzCkIlR"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# your code here\n",
    "model = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IQ-WoGxGXtNK"
   },
   "source": [
    "**Compiling the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nIM8tff5rhGE"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQqny85blh7n"
   },
   "source": [
    "**Find the accuracy of the model before training using `Model.evaluate()` method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hq9iYZHJk_zs"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8rGAeSIHpeuh"
   },
   "source": [
    "### Training and validating your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o1fSJU9vpouM"
   },
   "source": [
    "**Setting aside a validation set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dO_kde4MpfLj"
   },
   "outputs": [],
   "source": [
    "x_val = x_train_emb[:10000]\n",
    "partial_x_train = x_train_emb[10000:]\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D-pUD0swphAX"
   },
   "source": [
    "We use a validation set to evaluate the model during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlxAHYDwXtNL"
   },
   "source": [
    "**Training your model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rQARCg02XtNL"
   },
   "outputs": [],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vIjDeIt3XtNL"
   },
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fm12En9-XtNL"
   },
   "source": [
    "**Plotting the training and validation loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j1SQfvzLruaG"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fqKxiCF3XtNL"
   },
   "outputs": [],
   "source": [
    "#Solution\n",
    "import matplotlib.pyplot as plt\n",
    "history_dict = history.history\n",
    "loss_values = history_dict[\"loss\"]\n",
    "val_loss_values = history_dict[\"val_loss\"]\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss_values, \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TnVcT0JzXtNL"
   },
   "source": [
    "**Plotting the training and validation accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bwT7ym_-XtNL"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lV66CBgyXtNL"
   },
   "source": [
    "**Retraining a model from scratch on all training data (without a validation set) and stopping the training at the epoch where overfitting begins.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fvAeu_6Cryds"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KcYkfvw6qtra"
   },
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p5cBwq_ar0wR"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wSghre-4XtNL"
   },
   "outputs": [],
   "source": [
    "results = model.evaluate(x_test_emb, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_vMmaOM3XtNL"
   },
   "source": [
    "### Print the predicted label for the first 10 test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IwlsWOqgr3sf"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
